{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UG9Tomyzdsg2"
      },
      "source": [
        "# YOLOv5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mzfz3Ob4dvHP",
        "outputId": "83c2ac2f-3371-4a48-d1a6-9fc38d79d1da"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "YOLOv5 ðŸš€ v7.0-108-g4db6757 Python-3.8.10 torch-1.13.1+cu116 CPU\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Setup complete âœ… (2 CPUs, 12.7 GB RAM, 24.4/225.8 GB disk)\n"
          ]
        }
      ],
      "source": [
        "# !git clone https://github.com/ultralytics/yolov5  # clone\n",
        "# %cd yolov5\n",
        "# %pip install -qr requirements.txt  # install\n",
        "\n",
        "# import torch\n",
        "# import utils\n",
        "# display = utils.notebook_init()  # checks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python detect.py --weights yolov5s.pt --img 640 --conf 0.25 --source data/images\n",
        "# display.Image(filename='runs/detect/exp/zidane.jpg', width=600)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mTh0SWcCc2uq"
      },
      "source": [
        "# DocExtractor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "StwdoNzPc5Dn"
      },
      "outputs": [],
      "source": [
        "# Add code to sys.path\n",
        "import sys\n",
        "sys.path.append('../src')\n",
        "\n",
        "# Display\n",
        "from IPython.display import display, HTML\n",
        "display(HTML(\"<style>.container { width:95% !important; }</style>\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u8MkC_S7en-m"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Select GPU ID\n",
        "import os\n",
        "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"3\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BJe32_E5eqlf"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from models import load_model_from_path\n",
        "from utils import coerce_to_path_and_check_exist\n",
        "from utils.path import MODELS_PATH\n",
        "from utils.constant import MODEL_FILE\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "TAG = 'default'\n",
        "model_path = coerce_to_path_and_check_exist(MODELS_PATH / TAG / MODEL_FILE)\n",
        "model, (img_size, restricted_labels, normalize) = load_model_from_path(model_path, device=device, attributes_to_return=['train_resolution', 'restricted_labels', 'normalize'])\n",
        "_ = model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zTbXMPKae4z6"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "import numpy as np\n",
        "from utils.image import resize\n",
        "\n",
        "img = Image.open('img.jpg')\n",
        "\n",
        "# Resize \n",
        "img = resize(img, img_size)\n",
        "print(f'image size is: {img.size}')\n",
        "\n",
        "# Normalize and convert to Tensor\n",
        "inp = np.array(img, dtype=np.float32) / 255\n",
        "if normalize:\n",
        "    inp = ((inp - inp.mean(axis=(0, 1))) / (inp.std(axis=(0, 1)) + 10**-7))\n",
        "inp = torch.from_numpy(inp.transpose(2, 0, 1)).float().to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y9xaQSIVe7yz"
      },
      "outputs": [],
      "source": [
        "from utils.constant import LABEL_TO_COLOR_MAPPING\n",
        "from utils.image import LabeledArray2Image\n",
        "\n",
        "# compute prediction\n",
        "pred = model(inp.reshape(1, *inp.shape))[0].max(0)[1].cpu().numpy()\n",
        "\n",
        "# Retrieve good color mapping and transform to image\n",
        "restricted_colors = [LABEL_TO_COLOR_MAPPING[l] for l in restricted_labels]\n",
        "label_idx_color_mapping = {restricted_labels.index(l) + 1: c for l, c in zip(restricted_labels, restricted_colors)}\n",
        "pred_img = LabeledArray2Image.convert(pred, label_idx_color_mapping)\n",
        "\n",
        "# Blend predictions with original image\n",
        "mask = Image.fromarray((np.array(pred_img) == (0, 0, 0)).all(axis=-1).astype(np.uint8) * 127 + 128)\n",
        "blend_img = Image.composite(img, pred_img, mask)\n",
        "blend_img"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
